## ML lec03 : How to minimize cost in Linear Regression
Linear Regression의 cost 최소화 알고리즘의 원리 설명

### Simplified Hypothesis
- [ ] (TBD) 3:44
- $cost(W)$의 function을 그려보기
- Minimize한 값은 어떻게 찾을 수 있을까? → Gradient descent algorithm(경사하강법)

### Gradient descent algorithm
- Gradient descent is used many **minimization** problems
- 어떻게 가장 낮은 지점을 찾을 수 있을까?
  - 아무 값에서 시작(any other value)
  - $cost(W,b)$ 값을 변화시키며 값을 최소화하는 지점 찾기
- 경사도를 구하는 방법 → 미분
  - [ ] (TBD) Coursera 과정 정리한거 link

### Convex function
- 처음 시작점에 따라 도착 지점이 달라지는 문제 발생
- [ ] Convex function이란? → 어느 지점에서 시작하더라도 항상 도착하는 지점이 동일
  - 이는 Gradient descnet algorithm이 항상 답을 찾을 수 있음을 의미
  - **따라서 cost function을 설계할 때 cost function의 모양이 Convex function이 되는지 확인해야 한다**

## ML lab03 : Linear Regression의 Minimize cost, TensorFlow로 구현하기
